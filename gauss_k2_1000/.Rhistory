theme_bw()
ggplot(df,aes(x=lag,y=acf)) +
geom_line()+
geom_vline(xintercept=12*1:8,color='red',linetype='dashed',size=0.5) +
facet_grid(rows=vars(model)) +
ylim(-1,1)+
theme_bw()
ggplot(df,aes(x=lag,y=acf)) +
geom_line()+
geom_vline(xintercept=12*1:8,color='red',linetype='dashed',size=0.5) +
scale_x_axis(breaks=12*(1:8))
ggplot(df,aes(x=lag,y=acf)) +
geom_line()+
geom_vline(xintercept=12*1:8,color='red',linetype='dashed',size=0.5) +
scale_x_continuous(breaks=12*(1:8))
ggplot(df,aes(x=lag,y=acf)) +
geom_line()+
geom_vline(xintercept=12*1:8,color='red',linetype='dashed',size=0.5) +
scale_x_continuous(breaks=12*(1:8)) +
facet_grid(rows=vars(model)) +
ylim(-1,1)+
theme_bw()
ggplot(df,aes(x=lag,y=acf)) +
geom_line()+
geom_vline(xintercept=12*1:8,color='red',linetype='dashed',size=0.5) +
scale_x_continuous(breaks=12*(1:8)) +
facet_grid(rows=vars(model)) +
ylim(-1,1)+
ggtitle('Comparing idealised Seasonal Models via their ACF') +
xlab('Lag') + ylab('ACF') +
theme_bw()
ggplot(df,aes(x=lag,y=acf)) +
geom_line()+
geom_vline(xintercept=12*1:8,color='red',linetype='dashed',size=0.3) +
scale_x_continuous(breaks=12*(1:8)) +
facet_grid(rows=vars(model)) +
ylim(-1,1)+
ggtitle('Comparing idealised Seasonal Models via their ACF') +
xlab('Lag') + ylab('ACF') +
theme_bw()
ggplot(df,aes(x=lag,y=acf)) +
geom_line()+
geom_vline(xintercept=12*1:8,color='red',linetype='dashed',size=0.3) +
scale_x_continuous(breaks=12*(1:8)) +
facet_grid(rows=vars(model)) +
ylim(-1,1)+
ggtitle('Comparing idealised Seasonal Models via their ACF') +
xlab('Lag') + ylab('ACF') +
theme_bw() +
theme(
panel.background = theme_rect(fill = "transparent",colour = NA),
panel.grid.minor = theme_blank(),
panel.grid.major = theme_blank()
)
ggplot(df,aes(x=lag,y=acf)) +
geom_line()+
geom_vline(xintercept=12*1:8,color='red',linetype='dashed',size=0.3) +
scale_x_continuous(breaks=12*(1:8)) +
facet_grid(rows=vars(model)) +
ylim(-1,1)+
ggtitle('Comparing idealised Seasonal Models via their ACF') +
xlab('Lag') + ylab('ACF') +
theme_bw() +
theme(
panel.background = element_rect(fill = "transparent",colour = NA),
panel.grid.minor = element_blank(),
panel.grid.major = element_blank()
)
ggplot(df,aes(x=lag,y=acf)) +
geom_line()+
geom_vline(xintercept=12*1:8,color='red',linetype='dashed',size=0.3) +
scale_x_continuous(breaks=12*(1:8)) +
facet_grid(rows=vars(model)) +
ylim(-1,1)+
ggtitle('Comparing idealised Seasonal Models via their ACF') +
xlab('Lag') + ylab('ACF') +
theme_bw() +
theme(
panel.background = element_rect(fill = "transparent",colour = NA),
plot.background = element_rect(fill = "transparent", colour = NA),
panel.grid.minor = element_blank(),
panel.grid.major = element_blank()
)
ggsave('~/UniWork/ggbr Research/ANZSC 2021 talk/acf1.png',bg='transparent')
ggsave('~/UniWork/Ggbr Research/ANZSC 2021 talk/acf1.png',bg='transparent')
ggplot(df,aes(x=lag,y=acf)) +
geom_line()+
geom_vline(xintercept=12*1:8,color='red',linetype='dashed',size=0.3) +
scale_x_continuous(breaks=12*(1:8)) +
facet_grid(rows=vars(model)) +
ylim(-1,1)+
ggtitle('Comparing idealised Seasonal Models via their ACF') +
xlab('Lag') + ylab('ACF') +
theme_bw() +
theme(
panel.background = element_rect(fill = "transparent",colour = NA),
plot.background = element_rect(fill = "transparent", colour = NA),
panel.grid.minor = element_blank(),
panel.grid.major = element_blank(),
strip.text=element_text(size=12)
)
ggplot(df,aes(x=lag,y=acf)) +
geom_line()+
geom_vline(xintercept=12*1:8,color='red',linetype='dashed',size=0.3) +
scale_x_continuous(breaks=12*(1:8)) +
facet_grid(rows=vars(model)) +
ylim(-1,1)+
ggtitle('Comparing idealised Seasonal Models via their ACF') +
xlab('Lag') + ylab('ACF') +
theme_bw() +
theme(
panel.background = element_rect(fill = "transparent",colour = NA),
plot.background = element_rect(fill = "transparent", colour = NA),
panel.grid.minor = element_blank(),
panel.grid.major = element_blank(),
strip.text=element_text(size=12),
axis.text=element_text(size=10)
)
ggplot(df,aes(x=lag,y=acf)) +
geom_line()+
geom_vline(xintercept=12*1:8,color='red',linetype='dashed',size=0.3) +
scale_x_continuous(breaks=12*(1:8)) +
facet_grid(rows=vars(model)) +
ylim(-1,1)+
ggtitle('Comparing idealised Seasonal Models via their ACF') +
xlab('Lag') + ylab('ACF') +
theme_bw() +
theme(
panel.background = element_rect(fill = "transparent",colour = NA),
plot.background = element_rect(fill = "transparent", colour = NA),
panel.grid.minor = element_blank(),
panel.grid.major = element_blank(),
strip.text=element_text(size=14),
axis.text=element_text(size=12)
)
ggsave('~/UniWork/Ggbr Research/ANZSC 2021 talk/acf1.png',bg='transparent')
df <- rbind(data.frame(lag=1:100,model='Box-Jenkins Seasonal (P=1)',acf=bj_acf),
data.frame(lag=1:100,model='Gegenbauer Seasonal',acf=ggbr_acf))
ggplot(df,aes(x=lag,y=acf)) +
geom_line()+
geom_vline(xintercept=12*1:8,color='red',linetype='dashed',size=0.3) +
scale_x_continuous(breaks=12*(1:8)) +
facet_grid(rows=vars(model)) +
ylim(-1,1)+
ggtitle('Comparing idealised Seasonal Models via their ACF') +
xlab('Lag') + ylab('ACF') +
theme_bw() +
theme(
panel.background = element_rect(fill = "transparent",colour = NA),
plot.background = element_rect(fill = "transparent", colour = NA),
panel.grid.minor = element_blank(),
panel.grid.major = element_blank(),
strip.text=element_text(size=14),
axis.text=element_text(size=12)
)
ggsave('~/UniWork/Ggbr Research/ANZSC 2021 talk/acf1.png',bg='transparent')
library(tidyverse)
library(hypergeo)
library(hypergeo)
library(tidyverse)
library(hypergeo)
alpha <- 0.6
delta <- 0.6
rho <- numeric(101)
alpha2 <- alpha^2
psi_j <- 1
for (j in 0:100) {
if (j>0) psi_j <- psi_j * alpha *(j+delta)/(j+1.0)
f <- hypergeo(delta,j+delta,j+1,alpha2)
rho[j+1] <- psi_j * f
}
rho <- numeric(101)
alpha2 <- alpha^2
psi_j <- 1
for (j in 0:100) {
if (j>0) psi_j <- psi_j * alpha *(j+delta)/(j+1.0)
f <- Re(hypergeo(delta,j+delta,j+1,alpha2))
rho[j+1] <- psi_j * f
}
rho <- rho / rho[1]
rho <- rho[2:100]
df <- rbind(data.frame(lag=1:100,model='Box-Jenkins Seasonal (P=1)',acf=bj_acf),
data.frame(lag=1:100,model='Gegenbauer Seasonal',acf=ggbr_acf),
data.frame(lag=1:100,model='GAR(1)',acf=rho))
ggplot(df,aes(x=lag,y=acf)) +
geom_line()+
geom_vline(xintercept=12*1:8,color='red',linetype='dashed',size=0.3) +
scale_x_continuous(breaks=12*(1:8)) +
facet_grid(rows=vars(model)) +
ylim(-1,1)+
ggtitle('Comparing idealised Seasonal Models via their ACF') +
xlab('Lag') + ylab('ACF') +
theme_bw() +
theme(
panel.background = element_rect(fill = "transparent",colour = NA),
plot.background = element_rect(fill = "transparent", colour = NA),
panel.grid.minor = element_blank(),
panel.grid.major = element_blank(),
strip.text=element_text(size=14),
axis.text=element_text(size=12)
)
alpha <- 0.6
delta <- 0.6
rho <- numeric(101)
alpha2 <- alpha^2
psi_j <- 1
for (j in 0:100) {
if (j>0) psi_j <- psi_j * alpha *(j+delta)/(j+1.0)
f <- Re(hypergeo(delta,j+delta,j+1,alpha2))
rho[j+1] <- psi_j * f
}
rho <- rho / rho[1]
rho <- rho[2:101]
df <- rbind(data.frame(lag=1:100,model='Box-Jenkins Seasonal (P=1)',acf=bj_acf),
data.frame(lag=1:100,model='Gegenbauer Seasonal',acf=ggbr_acf),
data.frame(lag=1:100,model='GAR(1)',acf=rho))
ggplot(df,aes(x=lag,y=acf)) +
geom_line()+
geom_vline(xintercept=12*1:8,color='red',linetype='dashed',size=0.3) +
scale_x_continuous(breaks=12*(1:8)) +
facet_grid(rows=vars(model)) +
ylim(-1,1)+
ggtitle('Comparing idealised Seasonal Models via their ACF') +
xlab('Lag') + ylab('ACF') +
theme_bw() +
theme(
panel.background = element_rect(fill = "transparent",colour = NA),
plot.background = element_rect(fill = "transparent", colour = NA),
panel.grid.minor = element_blank(),
panel.grid.major = element_blank(),
strip.text=element_text(size=14),
axis.text=element_text(size=12)
)
omega <- seq(0,pi,by=0.001)
alpha<-0.4
delta<-0.8
p<-12
omega <- seq(0,pi,by=0.001)
f<-(q+alpha^2+2*alpha*cos(p*omega))^(-delta)/(2*pi)
f<-(1+alpha^2+2*alpha*cos(p*omega))^(-delta)/(2)
plot(omega,f,type='l')
delta<-1
p<-12
omega <- seq(0,pi,by=0.001)
f<-(1+alpha^2+2*alpha*cos(p*omega))^(-delta)/(2)
plot(omega,f,type='l')
p<-288
omega <- seq(0,pi,by=0.001)
f<-(1+alpha^2+2*alpha*cos(p*omega))^(-delta)/(2)
plot(omega,f,type='l')
delta<-0.3
p<-288
omega <- seq(0,pi,by=0.001)
f<-(1+alpha^2+2*alpha*cos(p*omega))^(-delta)/(2)
plot(omega,f,type='l')
p<-12
omega <- seq(0,pi,by=0.001)
f<-(1+alpha^2+2*alpha*cos(p*omega))^(-delta)/(2)
plot(omega,f,type='l')
library(hypergeo)
(1+1.4^2)/2.8
(1+1.5^2)/3
1.5^2
alpha <- seq(0.1,5.0,by=0.01)
aa <- (1+alpha^2)/(2*alpha)
plot(alpha,aa,type='l')
alpha <- seq(-5.0,-0.1,by=0.01)
aa <- (1+alpha^2)/(2*alpha)
plot(alpha,aa,type='l')
plot(alpha,acos(aa),type='l')
plot(alpha,acos(complex(aa)),type='l')
plot(alpha,acos(complex(real=aa)),type='l')
acos(complex(real=aa))
plot(alpha,Mod(acos(complex(real=aa))),type='l')
alpha <- seq(0.1,5.0,by=0.01)
aa <- (1+alpha^2)/(2*alpha)
plot(alpha,Mod(acos(complex(real=aa))),type='l')
library(pracma)
library(Rsolnp)
library(nloptr)
library(waveslim)
setwd("/home/richard/UniWork/Ggbr Research/Simulations Paper/sims/20210409/gauss_k2_1000")
# generic optimize function
sim_optim<-function(par, objective, lower, upper, ...) {
# check pars
for (i in 1:length(par))
if (par[i]<=lower[i]|par[i]>=upper[i]) par[i]<- (lower[i]+upper[i])/2   # if below lower bound then set to middle value
res <- solnp(par, objective, LB=lower, UB=upper, control=list(tol=1e-12,trace=0), ...)
if (res$convergence!=0)
lbfgs(par, objective, lower=lower, upper=upper, control=list(maxeval=500), ...)
else res$par <- res$pars
return(res)
}
# find 2 largest spikes in spectrum
big_spikes<-function(ss) {
# find freq 0.1
start_idx <- which.min(abs(ss$freq-0.1))
end_idx <- length(ss$spec)
spec <- ss$spec[start_idx:end_idx]
freq <- ss$freq[start_idx:end_idx]
spike1 <- which.max(spec)
for (i in (spike1-5):(spike1+5)) if (i>0&i<length(spec)) spec[i] <- 0
spike2 <- which.max(spec)
return(list(f1=freq[spike1],f2=freq[spike2]))
}
# Wavelets
# first we re-define the standard function to force it to ignore the low-frequency peak from the AR(1) component
# the standard version gets confused by this and reports the g-frequency to be low.
spp.mle.mod <- function(y, wf, J=log(length(y),2)-1, p=0.01, frac=1)
{
##
##  g a u s s g k . R  Adapitve Gauss-Kronrod
##
# We re-define this funtion as the default can generate many errors around the unbounded peak in the spectral density.
quadgk <- function(f, a, b, tol = .Machine$double.eps^0.5, ...) {
stopifnot(is.numeric(a), length(a) == 1,
is.numeric(b), length(b) == 1)
eps <- .Machine$double.eps
fun <- match.fun(f)
f <- function(x) fun(x, ...)
if (a == b)     return(0)
else if (a > b) return(-1 * quadgk(f, b, a, tol = tol))
# Nodes and weights for Gauss-Kronrod (7, 15)
n15 <- c(-0.9914553711208126, -0.9491079123427585, -0.8648644233597691,
-0.7415311855993944, -0.5860872354676911, -0.4058451513773972,
-0.2077849550078985,  0.0,                 0.2077849550078985,
0.4058451513773972,  0.5860872354676911,  0.7415311855993944,
0.8648644233597691,  0.9491079123427585,  0.9914553711208126)
n7  <- c(-0.9491079123427585, -0.7415311855993944, -0.4058451513773972,
0.0,
0.4058451513773972, 0.7415311855993944,  0.9491079123427585)
w15 <- c(0.02293532201052922, 0.06309209262997855,  0.1047900103222502,
0.1406532597155259,  0.1690047266392679,   0.1903505780647854,
0.2044329400752989,  0.2094821410847278,   0.2044329400752989,
0.1903505780647854,  0.1690047266392679,   0.1406532597155259,
0.1047900103222502,  0.06309209262997855,  0.02293532201052922)
w7  <- c(0.1294849661688697,  0.2797053914892767,   0.3818300505051189,
0.4179591836734694,
0.3818300505051189,  0.2797053914892767,   0.1294849661688697)
.gkadpt <- function(f, a, b, tol = tol) {
# use nodes and weights from the environment
x15 <- 0.5 * ((b - a) * n15 + b + a)
x7  <- 0.5 * ((b - a) * n7  + b + a)
f7<-f(x7)
if (length(which(is.infinite(f7)))) {
n<-which(is.infinite(f7))
for (nn in n) if (nn==7) f7[7]<-f7[6] else f7[nn]<-f7[nn+1]
}
f15<-f(x15)
if (length(which(is.infinite(f15)))) {
n<-which(is.infinite(f15))
for (nn in n) if (nn==15) f15[15]<-f15[14] else f15[nn]<-f15[nn+1]
}
Q7  <- sum(w7  * f7)  * (b-a)/2
Q15 <- sum(w15 * f15) * (b-a)/2
if (!is.finite(Q7) || !is.finite(Q15)) {
#warning("Infinite or NA function value encountered.")
return(Q15)
} else if (abs(Q15 - Q7) < tol) {
return(Q15)
} else if (abs(b-a) < 16*eps) {
#warning("Minimum step size reached; singularity possible.")
return(Q15)
} # else
Q2 <- .gkadpt(f, (a+b)/2, b, tol = tol)
Q1 <- .gkadpt(f, a, (a+b)/2, tol = tol)
return(Q1 + Q2)
}
# start the recursive procedure
.gkadpt(f, a, b, tol = tol)
}
spp.ar1.sdf <- function(freq, ll)
{return(
abs(2 * (cos(2*pi*freq) - cos(2*pi*ll$f1)))^(-2*ll$d1) *
abs(2 * (cos(2*pi*freq) - cos(2*pi*ll$f2)))^(-2*ll$d2) /
(1-2*ll$phi*cos(2*pi*freq)+ll$phi^2))}
bandpass.spp.ar1 <- function(a, b, d1, f1, d2, f2, phi) {
# We change this to use Gauss-Konrad quadrature rather than the standard R "integrate" function
# which had problems with the unbounded peak.
if ( (f1 > a && f1 < b) && (f2<a||f2>b) ) {
result1 <- quadgk(spp.ar1.sdf, a, f1, ll=list(d1=d1, f1=f1, d2=d2, f2=f2, phi=phi))
result2 <- quadgk(spp.ar1.sdf, f1, b, ll=list(d1=d1, f1=f1, d2=d2, f2=f2, phi=phi))
result3 <- 0
} else if ( (f2 > a && f2 < b) && (f1<a||f1>b) ) {
result1 <- quadgk(spp.ar1.sdf, a, f2, ll=list(d1=d1, f1=f1, d2=d2, f2=f2, phi=phi))
result2 <- quadgk(spp.ar1.sdf, f2, b, ll=list(d1=d1, f1=f1, d2=d2, f2=f2, phi=phi))
result3 <- 0
} else if ( (f1 > a && f1 < b) && (f2 > a && f2 < b)) {
if (f1<f2) {
result1 <- quadgk(spp.ar1.sdf, a, f1, ll=list(d1=d1, f1=f1, d2=d2, f2=f2, phi=phi))
result2 <- quadgk(spp.ar1.sdf, f1, f2, ll=list(d1=d1, f1=f1, d2=d2, f2=f2, phi=phi))
result3 <- quadgk(spp.ar1.sdf, f2, b, ll=list(d1=d1, f1=f1, d2=d2, f2=f2, phi=phi))
} else {
result1 <- quadgk(spp.ar1.sdf, a, f2, ll=list(d1=d1, f1=f1, d2=d2, f2=f2, phi=phi))
result2 <- quadgk(spp.ar1.sdf, f2, f1, ll=list(d1=d1, f1=f1, d2=d2, f2=f2, phi=phi))
result3 <- quadgk(spp.ar1.sdf, f1, b, ll=list(d1=d1, f1=f1, d2=d2, f2=f2, phi=phi))
}
}
else {
result1 <- quadgk(spp.ar1.sdf, a, b, ll=list(d1=d1, f1=f1, d2=d2, f2=f2, phi=phi))
result2 <- result3 <- 0
}
return(2*(result1 + result2 + result3))
}
sppLL <- function(x, y) {
d1 <- x[1]
f1 <- x[2]
d2 <- x[3]
f2 <- x[4]
phi <- x[5]
y.dwpt <- y[[1]]
y.basis <- y[[2]]
n <- y[[3]]
J <- y[[4]]
## Establish the limits of integration for the band-pass variances
a <- unlist(apply(matrix(2^(1:J)-1), 1, seq, from=0, by=1)) / 2^(rep(1:J, 2^(1:J))) / 2
b <- unlist(apply(matrix(2^(1:J)), 1, seq, from=1, by=1)) / 2^(rep(1:J, 2^(1:J))) / 2
## Define some useful parameters for the wavelet packet tree
length.jn <- n / rep(2^(1:J), 2^(1:J))
scale.jn <- rep(2^(1:J+1), 2^(1:J))
## Initialize various parameters for the reduced LL
Basis <- (1:length(y.basis))[y.basis]
bp.var <- numeric(length(Basis))
delta.n <- 100
## Compute the band-pass variances according to \delta and f_G
omega.diag <- NULL
for(i in 1:sum(y.basis)) {
jn <- Basis[i]
bp.var[i] <- bandpass.spp.ar1(a[jn], b[jn], d1, f1, d2, f2, phi)
# If we get infinities, replace with a large number
if (is.infinite(bp.var[i])) bp.var[i]<- 1e15
omega.diag <- c(omega.diag, scale.jn[jn] * rep(bp.var[i], length.jn[jn]))
}
## Compute reduced log-likelihood
rLL <- n * log(1/n * sum(y.dwpt^2 / omega.diag, na.rm=TRUE)) + sum(length.jn[y.basis] * log(scale.jn[y.basis] * bp.var))
rLL
}
n <- length(y)
x0 <- numeric(5)
## Perform discrete wavelet packet transform (DWPT) on Y
y.dwpt <- dwpt(y, wf, n.levels=J)
n <- length(y)
if(frac < 1) {
for(i in 1:length(y.dwpt)) {
vec <- y.dwpt[[i]]
ni <- length(vec)
j <- rep(1:J, 2^(1:J))[i]
vec[trunc(frac * n/2^j):ni] <- NA
y.dwpt[[i]] <- vec
}
}
y.basis <- as.logical(ortho.basis(portmanteau.test(y.dwpt, p)))
y.dwpt <- as.matrix(unlist(y.dwpt[y.basis]))
## Compute initial estimate of the Gegenbauer frequency
ss<-spectrum(y,plot=FALSE,detrend=FALSE,demean=FALSE,method='pgram',taper=0,fast=FALSE)
spikes <- big_spikes(ss)
x0[2] <- spikes[['f1']]
x0[4] <- spikes[['f2']]
# y.per <- per(y - mean(y))
# y.per1<-y.per
# y.per1[1:as.integer(n/10)]<-0
# x0[2] <- (0:(n/2)/n)[max(y.per1) == y.per1]
## Compute initial estimate of the fractional difference parameter
muJ <- (unlist(apply(matrix(2^(1:J)-1), 1, seq, from=0, by=1)) / 2^(rep(1:J, 2^(1:J))) +
unlist(apply(matrix(2^(1:J)), 1, seq, from=1, by=1)) / 2^(rep(1:J, 2^(1:J)))) / 4
y.modwpt <- modwpt(y, wf=wf, n.levels=J)
y.varJ <- rep(2^(1:J), 2^(1:J)) * unlist(lapply(y.modwpt, FUN=function(x)sum(x*x,na.rm=TRUE)/length(x[!is.na(x)])))
lb <- c(0.025,0.1,0.025,0.1,-0.999)
ub <- c(0.475,0.5,0.475,0.5,0.999)
x0[1] <- x0[3] <- 0.25
# x0[1] <- min(-0.5 * lsfit(log(abs(muJ[y.basis] - x0[2])), log(y.varJ[y.basis]))$coef[2], 0.49)
# if (x0[1]<=0) x0[1]<- (lb[1]+ub[1])/2   # if below lower bound then set to middle value
# x0[3] <- min(-0.5 * lsfit(log(abs(muJ[y.basis] - x0[4])), log(y.varJ[y.basis]))$coef[2], 0.49)
# if (x0[3]<=0) x0[3]<- (lb[3]+ub[3])/2   # if below lower bound then set to middle value
x0[5] <- 0    # Initial estimate for phi
result <- sim_optim(x0, sppLL, lower=lb, upper=ub, y=list(y.dwpt, y.basis, n, J))
return(result)
}
# find 2 largest spikes in spectrum
big_spikes<-function(ss) {
# find freq 0.1
start_idx <- which.min(abs(ss$freq-0.1))
end_idx <- length(ss$spec)
spec <- ss$spec[start_idx:end_idx]
freq <- ss$freq[start_idx:end_idx]
spike1 <- which.max(spec)
for (i in (spike1-5):(spike1+5)) if (i>0&i<length(spec)) spec[i] <- 0
spike2 <- which.max(spec)
return(list(f1=freq[spike1],f2=freq[spike2]))
}
# Find Wavelet Estimates for GAR(1)
wavelet.est<-function(y,filter){
flag<-TRUE
par1<-c(NA,NA,NA,NA,NA)
tryCatch(par1<-spp.mle.mod(y, filter)$par, error = function(e) flag<-FALSE)
#par1<-spp.mle.mod(y, filter)$par
if (!is.na(par1[1])) {
return(c(d1=par1[1],f1=par1[2],d2=par1[3],f2=par1[4],phi=par1[5]))
} else return(c(NA,NA,NA,NA,NA))
}
synProcess1000 <- readRDS('syn_k2gauss1000.rds')
yd<-c(synProcess1000$y1,rep(0,12))
wavelet.est(yd,"mb8")
tryCatch(par1<-spp.mle.mod(yd, filter)$par, error = function(e) flag<-FALSE)
flag<-TRUE
par1<-c(NA,NA,NA,NA,NA)
tryCatch(par1<-spp.mle.mod(yd, filter)$par, error = function(e) flag<-FALSE)
wavelet.est(yd,"MB8")
par1<-spp.mle.mod(y, filter)$par
par1<-spp.mle.mod(yd, filter)$par
yd<-c(synProcess1000$y1,rep(0,24))
wavelet.est(yd,"mb8")
